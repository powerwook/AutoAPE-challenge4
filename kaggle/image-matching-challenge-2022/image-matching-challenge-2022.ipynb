{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb308aa",
   "metadata": {
    "papermill": {
     "duration": 0.029091,
     "end_time": "2023-06-18T05:59:39.834654",
     "exception": false,
     "start_time": "2023-06-18T05:59:39.805563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LoFTR + QuadTree Attention Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ce42e1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-18T05:59:39.885920Z",
     "iopub.status.busy": "2023-06-18T05:59:39.885263Z",
     "iopub.status.idle": "2023-06-18T05:59:41.736265Z",
     "shell.execute_reply": "2023-06-18T05:59:41.735495Z"
    },
    "papermill": {
     "duration": 1.879305,
     "end_time": "2023-06-18T05:59:41.738618",
     "exception": false,
     "start_time": "2023-06-18T05:59:39.859313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, csv\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython import display\n",
    "import PIL\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.cm as cm\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13f7ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T05:59:41.789846Z",
     "iopub.status.busy": "2023-06-18T05:59:41.789234Z",
     "iopub.status.idle": "2023-06-18T05:59:41.793051Z",
     "shell.execute_reply": "2023-06-18T05:59:41.792372Z"
    },
    "papermill": {
     "duration": 0.031549,
     "end_time": "2023-06-18T05:59:41.794972",
     "exception": false,
     "start_time": "2023-06-18T05:59:41.763423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = '/kaggle/input/image-matching-challenge-2022/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35f93fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T05:59:41.847640Z",
     "iopub.status.busy": "2023-06-18T05:59:41.847416Z",
     "iopub.status.idle": "2023-06-18T05:59:41.850661Z",
     "shell.execute_reply": "2023-06-18T05:59:41.850010Z"
    },
    "papermill": {
     "duration": 0.03336,
     "end_time": "2023-06-18T05:59:41.852447",
     "exception": false,
     "start_time": "2023-06-18T05:59:41.819087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dry_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718620a1",
   "metadata": {
    "papermill": {
     "duration": 0.027749,
     "end_time": "2023-06-18T05:59:41.905648",
     "exception": false,
     "start_time": "2023-06-18T05:59:41.877899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download and Import Quadree attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907d647c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T05:59:41.964275Z",
     "iopub.status.busy": "2023-06-18T05:59:41.964004Z",
     "iopub.status.idle": "2023-06-18T06:02:30.701152Z",
     "shell.execute_reply": "2023-06-18T06:02:30.700235Z"
    },
    "papermill": {
     "duration": 168.769171,
     "end_time": "2023-06-18T06:02:30.703536",
     "exception": false,
     "start_time": "2023-06-18T05:59:41.934365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/working/quadtreeattention/QuadTreeAttention-master/QuadTreeAttention\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l-\b \bdone\r\n",
      "\u001B[?25hBuilding wheels for collected packages: quadtree-attention-package\r\n",
      "  Building wheel for quadtree-attention-package (setup.py) ... \u001B[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001B[?25h  Created wheel for quadtree-attention-package: filename=quadtree_attention_package-0.0.0-cp37-cp37m-linux_x86_64.whl size=4851265 sha256=c0395afe60f71fb4a8116e2eb8189db5b17bf2fb22af3945c45d22414c2e6e48\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-twbekmw9/wheels/03/c8/60/dabd86cf4c17ee029f958aa299af101665521feae8b53a5177\r\n",
      "Successfully built quadtree-attention-package\r\n",
      "Installing collected packages: quadtree-attention-package\r\n",
      "Successfully installed quadtree-attention-package-0.0.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!cp -r /kaggle/input/quadtreeattention/ /kaggle/working/\n",
    "!cd /kaggle/working/quadtreeattention/QuadTreeAttention-master/QuadTreeAttention/ && pip install .\n",
    "\n",
    "sys.path.append('/kaggle/working/quadtreeattention/QuadTreeAttention-master/')\n",
    "sys.path.append('/kaggle/working/quadtreeattention/QuadTreeAttention-master/FeatureMatching/')\n",
    "sys.path.append('/kaggle/working/quadtreeattention/QuadTreeAttention-master/QuadTreeAttention/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e281f471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:02:30.771507Z",
     "iopub.status.busy": "2023-06-18T06:02:30.770051Z",
     "iopub.status.idle": "2023-06-18T06:04:02.311736Z",
     "shell.execute_reply": "2023-06-18T06:04:02.310665Z"
    },
    "papermill": {
     "duration": 91.578112,
     "end_time": "2023-06-18T06:04:02.314268",
     "exception": false,
     "start_time": "2023-06-18T06:02:30.736156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install /kaggle/input/igla-py-wheels/loguru-0.5.3-py3-none-any.whl\n",
    "!pip install /kaggle/input/igla-py-wheels/einops-0.4.1-py3-none-any.whl\n",
    "!pip install /kaggle/input/igla-py-wheels/timm-0.4.12-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3ea8d",
   "metadata": {
    "papermill": {
     "duration": 0.032071,
     "end_time": "2023-06-18T06:04:02.379462",
     "exception": false,
     "start_time": "2023-06-18T06:04:02.347391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize QuadTreeAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35483a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:04:02.446872Z",
     "iopub.status.busy": "2023-06-18T06:04:02.446194Z",
     "iopub.status.idle": "2023-06-18T06:04:02.486970Z",
     "shell.execute_reply": "2023-06-18T06:04:02.486284Z"
    },
    "papermill": {
     "duration": 0.076726,
     "end_time": "2023-06-18T06:04:02.488836",
     "exception": false,
     "start_time": "2023-06-18T06:04:02.412110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from FeatureMatching.src.config.default import get_cfg_defaults\n",
    "config = get_cfg_defaults()\n",
    "\n",
    "# INDOOT lofrt_ds_quadtree config\n",
    "config.LOFTR.MATCH_COARSE.MATCH_TYPE = 'dual_softmax'\n",
    "config.LOFTR.MATCH_COARSE.SPARSE_SPVS = False\n",
    "config.LOFTR.RESNETFPN.INITIAL_DIM = 128\n",
    "config.LOFTR.RESNETFPN.BLOCK_DIMS=[128, 196, 256]\n",
    "config.LOFTR.COARSE.D_MODEL = 256\n",
    "config.LOFTR.COARSE.BLOCK_TYPE = 'quadtree'\n",
    "config.LOFTR.COARSE.ATTN_TYPE = 'B'\n",
    "config.LOFTR.COARSE.TOPKS=[32, 16, 16]\n",
    "config.LOFTR.FINE.D_MODEL = 128\n",
    "config.TRAINER.WORLD_SIZE = 1 # 8\n",
    "config.TRAINER.CANONICAL_BS = 32\n",
    "config.TRAINER.TRUE_BATCH_SIZE = 1\n",
    "_scaling = 1\n",
    "config.TRAINER.ENABLE_PLOTTING = False\n",
    "config.TRAINER.SCALING = _scaling\n",
    "config.TRAINER.TRUE_LR = 1e-3 # 1e-4 config.TRAINER.CANONICAL_LR * _scaling\n",
    "config.TRAINER.WARMUP_STEP = 0 #math.floor(config.TRAINER.WARMUP_STEP / _scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7c9add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:04:02.554495Z",
     "iopub.status.busy": "2023-06-18T06:04:02.553669Z",
     "iopub.status.idle": "2023-06-18T06:04:17.117720Z",
     "shell.execute_reply": "2023-06-18T06:04:17.116880Z"
    },
    "papermill": {
     "duration": 14.599402,
     "end_time": "2023-06-18T06:04:17.120189",
     "exception": false,
     "start_time": "2023-06-18T06:04:02.520787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from FeatureMatching.src.utils.profiler import build_profiler\n",
    "from FeatureMatching.src.lightning.lightning_loftr import PL_LoFTR\n",
    "\n",
    "\n",
    "# lightning module\n",
    "qta_center_img_mask = False\n",
    "qta_max_img_size = 1024\n",
    "qta_torch_device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "\n",
    "\n",
    "qta_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "disable_ckpt = True\n",
    "qta_profiler_name = None # help='options: [inference, pytorch], or leave it unset\n",
    "qta_profiler = build_profiler(qta_profiler_name)\n",
    "qta_model = PL_LoFTR(config,\n",
    "                 pretrained_ckpt= \"../input/quadtreecheckpoints/outdoor_quadtree.ckpt\", # args.ckpt_path, from scratch atm\n",
    "                 profiler=qta_profiler)\n",
    "qta_matcher = qta_model.matcher\n",
    "qta_matcher.eval()\n",
    "qta_matcher.to(qta_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d419b38",
   "metadata": {
    "papermill": {
     "duration": 0.03322,
     "end_time": "2023-06-18T06:04:17.189743",
     "exception": false,
     "start_time": "2023-06-18T06:04:17.156523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Images Adjustment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650a59a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:04:17.258560Z",
     "iopub.status.busy": "2023-06-18T06:04:17.258278Z",
     "iopub.status.idle": "2023-06-18T06:04:17.271030Z",
     "shell.execute_reply": "2023-06-18T06:04:17.270198Z"
    },
    "papermill": {
     "duration": 0.049295,
     "end_time": "2023-06-18T06:04:17.273405",
     "exception": false,
     "start_time": "2023-06-18T06:04:17.224110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_loftr_image_origNEW(fname, img_w=480, img_h=832):\n",
    "    img0_raw = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_w > 0 and img_h > 0:\n",
    "        img0_raw = cv2.resize(img0_raw, (img_w, img_h))\n",
    "    img0 = torch.from_numpy(img0_raw)[None][None].cuda() / 255.\n",
    "    return img0\n",
    "\n",
    "\n",
    "def load_resized_image(fname, max_image_size):\n",
    "    img = cv2.imread(fname)\n",
    "    if max_image_size == -1:\n",
    "        # no resize\n",
    "        return img, 1.0\n",
    "    scale = max_image_size / max(img.shape[0], img.shape[1]) \n",
    "    w = int(img.shape[1] * scale)\n",
    "    h = int(img.shape[0] * scale)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    return img, scale\n",
    "\n",
    "\n",
    "def scale_to_resized(mkpts0, mkpts1, scale1, scale2):\n",
    "    ### scale to original im size because we used max_image_size\n",
    "    # first point\n",
    "    mkpts0[:, 0] = mkpts0[:, 0] / scale1\n",
    "    mkpts0[:, 1] = mkpts0[:, 1] / scale1\n",
    "    \n",
    "    # second point\n",
    "    mkpts1[:, 0] = mkpts1[:, 0] / scale2\n",
    "    mkpts1[:, 1] = mkpts1[:, 1] / scale2\n",
    "    \n",
    "    return mkpts0, mkpts1\n",
    "\n",
    "\n",
    "def put_img_on_disk(img, output_img_tag):\n",
    "    img_path_on_disk = f'/kaggle/working/{output_img_tag}.png'\n",
    "    cv2.imwrite(img_path_on_disk, img)\n",
    "    return img_path_on_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91fb310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:04:17.397883Z",
     "iopub.status.busy": "2023-06-18T06:04:17.397316Z",
     "iopub.status.idle": "2023-06-18T06:04:17.419211Z",
     "shell.execute_reply": "2023-06-18T06:04:17.418219Z"
    },
    "papermill": {
     "duration": 0.088254,
     "end_time": "2023-06-18T06:04:17.422012",
     "exception": false,
     "start_time": "2023-06-18T06:04:17.333758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_divide_size_smallest(im_size, coef):\n",
    "    # select size dividable by coef\n",
    "    if im_size % coef == 0:\n",
    "        # already dividable, just return original\n",
    "        return im_size\n",
    "    return round(((im_size / coef) + 0.5)) * coef\n",
    "\n",
    "\n",
    "def add_zero_padding_two_img_same(img1, img2, div_coef=32):\n",
    "    img1_height, img1_width, img1_channels = img1.shape\n",
    "    img2_height, img2_width, img2_channels = img2.shape\n",
    "    \n",
    "    # fit both images on canvas\n",
    "    max_width = max(img1_width, img2_width)\n",
    "    max_height = max(img1_height, img2_height) \n",
    "    \n",
    "    # use own width and height for image with zero-padding\n",
    "    result1, offset1 = create_zero_padding_img(img1, max_width, max_height, img1_channels, div_coef)\n",
    "    result2, offset2 = create_zero_padding_img(img2, max_width, max_height, img2_channels, div_coef)\n",
    "    \n",
    "    return result1, result2, offset1, offset2\n",
    "\n",
    "\n",
    "def create_zero_padding_img(img, max_im_width, max_im_height, channels, div_coef=32):\n",
    "    \n",
    "    # create new image of desired size and color (black) for padding\n",
    "    new_area_image_width = calc_divide_size_smallest(max_im_width, div_coef)\n",
    "    new_area_image_height = calc_divide_size_smallest(max_im_height, div_coef)\n",
    "    \n",
    "    im_height, im_width, im_channels = img.shape\n",
    "    if qta_center_img_mask:\n",
    "        x_offset = (new_area_image_width - im_width) // 2\n",
    "        y_offset = (new_area_image_height - im_height) // 2\n",
    "    else:\n",
    "        x_offset = 0\n",
    "        y_offset = 0\n",
    "    \n",
    "    im_right = x_offset + im_width # right of image corner where ends\n",
    "    im_bottom = y_offset + im_height # right of image corner where ends\n",
    "    \n",
    "    color = (0,0,0)\n",
    "    result = np.full((new_area_image_height, new_area_image_width, im_channels), color, dtype=np.uint8)\n",
    "    \n",
    "    # copy img image into center of result image\n",
    "    result[y_offset:im_bottom, x_offset:im_right] = img\n",
    "    \n",
    "    # return image and x,y of old image in a new image (frame)\n",
    "    return result, (x_offset, y_offset)\n",
    "\n",
    "\n",
    "def unpad_matches(mkpts0, mkpts1, offset_point1, offset_point2):\n",
    "    offset_x1, offset_y1 = offset_point1\n",
    "    offset_x2, offset_y2 = offset_point2\n",
    "\n",
    "    # remove offeset\n",
    "    mkpts0[:, 0] = mkpts0[:, 0] - offset_x1\n",
    "    mkpts0[:, 1] = mkpts0[:, 1] - offset_y1\n",
    "    \n",
    "    mkpts1[:, 0] = mkpts1[:, 0] - offset_x2\n",
    "    mkpts1[:, 1] = mkpts1[:, 1] - offset_y2\n",
    "    return mkpts0, mkpts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58231739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:04:17.517437Z",
     "iopub.status.busy": "2023-06-18T06:04:17.517023Z",
     "iopub.status.idle": "2023-06-18T06:04:17.532204Z",
     "shell.execute_reply": "2023-06-18T06:04:17.531378Z"
    },
    "papermill": {
     "duration": 0.064285,
     "end_time": "2023-06-18T06:04:17.534751",
     "exception": false,
     "start_time": "2023-06-18T06:04:17.470466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inf_qta(image_fpath_1, image_fpath_2, max_image_size=qta_max_img_size, divide_coef=32):\n",
    "\n",
    "    # resize image if we need\n",
    "    img1_resized, scale1 = load_resized_image(image_fpath_1, max_image_size)\n",
    "    img2_resized, scale2 = load_resized_image(image_fpath_2, max_image_size)\n",
    "\n",
    "    \n",
    "    ### add padding -> use same image padding mask because models wants it\n",
    "    pad_img1, pad_img2, pad_offset_p1, pad_offset_p2 = add_zero_padding_two_img_same(img1_resized, img2_resized, divide_coef)\n",
    "    \n",
    "        \n",
    "    # save temporarily    \n",
    "    img1_disk_path = put_img_on_disk(pad_img1, 'qta_img1')\n",
    "    img2_disk_path = put_img_on_disk(pad_img2, 'qta_img2')\n",
    "    \n",
    "    \n",
    "    # load withr loftr    \n",
    "    gray_img_1 = load_loftr_image_origNEW(img1_disk_path, -1, -1)\n",
    "    gray_img_2 = load_loftr_image_origNEW(img2_disk_path, -1, -1)\n",
    "    \n",
    "    batch = {'image0': gray_img_1, 'image1': gray_img_2}\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        qta_matcher.eval()\n",
    "        qta_matcher.to(qta_device)\n",
    "        \n",
    "        qta_matcher(batch)\n",
    "        mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "        mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "        mconf = batch['mconf'].cpu().numpy()\n",
    "    \n",
    "    ### unpad matches\n",
    "    mkpts0, mkpts1 = unpad_matches(mkpts0, mkpts1, pad_offset_p1, pad_offset_p2)\n",
    "    \n",
    "    ### scale to original im size because we used max_image_size\n",
    "    mkpts0, mkpts1 = scale_to_resized(mkpts0, mkpts1, scale1, scale2)\n",
    "    \n",
    "    \n",
    "    # cleanup\n",
    "    if os.path.exists(img1_disk_path): os.remove(img1_disk_path)\n",
    "    if os.path.exists(img2_disk_path): os.remove(img2_disk_path)\n",
    "    \n",
    "    return mkpts0, mkpts1, mconf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772cce1",
   "metadata": {
    "papermill": {
     "duration": 0.043262,
     "end_time": "2023-06-18T06:04:17.622345",
     "exception": false,
     "start_time": "2023-06-18T06:04:17.579083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kornia is Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5142833a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:04:17.711068Z",
     "iopub.status.busy": "2023-06-18T06:04:17.710667Z",
     "iopub.status.idle": "2023-06-18T06:06:22.542218Z",
     "shell.execute_reply": "2023-06-18T06:06:22.541216Z"
    },
    "papermill": {
     "duration": 124.879025,
     "end_time": "2023-06-18T06:06:22.544671",
     "exception": false,
     "start_time": "2023-06-18T06:04:17.665646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (21.3)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (1.9.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.8.1->kornia==0.6.4) (4.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->kornia==0.6.4) (3.0.7)\r\n",
      "Installing collected packages: kornia\r\n",
      "  Attempting uninstall: kornia\r\n",
      "    Found existing installation: kornia 0.5.8\r\n",
      "    Uninstalling kornia-0.5.8:\r\n",
      "      Successfully uninstalled kornia-0.5.8\r\n",
      "Successfully installed kornia-0.6.4\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mProcessing /kaggle/input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (3.5.1)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (4.5.4.60)\r\n",
      "Requirement already satisfied: kornia in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (0.6.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (1.9.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia->kornia-moons==0.1.9) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->kornia-moons==0.1.9) (4.1.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.4.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (9.0.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (4.30.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (3.0.7)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.21.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (0.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->kornia-moons==0.1.9) (1.16.0)\r\n",
      "Installing collected packages: kornia-moons\r\n",
      "Successfully installed kornia-moons-0.1.9\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mProcessing /kaggle/input/igla-py-wheels/loguru-0.5.3-py3-none-any.whl\r\n",
      "loguru is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mProcessing /kaggle/input/igla-py-wheels/einops-0.4.1-py3-none-any.whl\r\n",
      "einops is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n",
    "!pip install /kaggle/input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\n",
    "\n",
    "base_loftr_github = '/kaggle/input/loftrutils/LoFTR-master/LoFTR-master'\n",
    "sys.path.append(base_loftr_github)\n",
    "!pip install /kaggle/input/igla-py-wheels/loguru-0.5.3-py3-none-any.whl\n",
    "!pip install /kaggle/input/igla-py-wheels/einops-0.4.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a137127",
   "metadata": {
    "papermill": {
     "duration": 0.039435,
     "end_time": "2023-06-18T06:06:22.624735",
     "exception": false,
     "start_time": "2023-06-18T06:06:22.585300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LoFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdb69095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:06:22.707762Z",
     "iopub.status.busy": "2023-06-18T06:06:22.707445Z",
     "iopub.status.idle": "2023-06-18T06:06:22.729270Z",
     "shell.execute_reply": "2023-06-18T06:06:22.728599Z"
    },
    "papermill": {
     "duration": 0.067109,
     "end_time": "2023-06-18T06:06:22.731173",
     "exception": false,
     "start_time": "2023-06-18T06:06:22.664064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loftr original repo\n",
    "from src.loftr import LoFTR\n",
    "from src.utils.plotting import make_matching_figures\n",
    "from src.utils.comm import gather, all_gather\n",
    "from src.utils.misc import lower_config, flattenList\n",
    "from src.utils.profiler import PassThroughProfiler\n",
    "\n",
    "from src.loftr import default_cfg\n",
    "from src.config.default import get_cfg_defaults\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import kornia\n",
    "from kornia_moons.feature import *\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "\n",
    "def draw_img_match(img1, img2, mkpts0, mkpts1, inliers):\n",
    "    display_vertical = False\n",
    "    #img1.shape[1]/img1.shape[0]>0.8 or img2.shape[1]/img2.shape[0]>0.8\n",
    "    \n",
    "    draw_LAF_matches(\n",
    "    KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n",
    "                                torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n",
    "                                torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n",
    "\n",
    "    KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n",
    "                                torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n",
    "                                torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n",
    "    torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n",
    "    K.tensor_to_image(img1),\n",
    "    K.tensor_to_image(img2),\n",
    "    inliers,\n",
    "    draw_dict={'inlier_color': (0.2, 1, 0.2),\n",
    "               'tentative_color': None, \n",
    "               'feature_color': (0.2, 0.5, 1), 'vertical': display_vertical})\n",
    "    \n",
    "\n",
    "def load_torch_kornia_image(fname, device, max_image_size):\n",
    "    img,_ = load_resized_image(fname, max_image_size)\n",
    "    img = K.image_to_tensor(img, False).float() /255.\n",
    "    img = K.color.bgr_to_rgb(img)\n",
    "    orig_img_device = img.to(device)\n",
    "    return orig_img_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1c033",
   "metadata": {
    "papermill": {
     "duration": 0.039785,
     "end_time": "2023-06-18T06:06:22.810801",
     "exception": false,
     "start_time": "2023-06-18T06:06:22.771016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Quantify the quality of matched points\n",
    "## Save info into dictionary and write to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b946235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:06:22.891373Z",
     "iopub.status.busy": "2023-06-18T06:06:22.890695Z",
     "iopub.status.idle": "2023-06-18T06:06:22.895617Z",
     "shell.execute_reply": "2023-06-18T06:06:22.894921Z"
    },
    "papermill": {
     "duration": 0.047381,
     "end_time": "2023-06-18T06:06:22.897444",
     "exception": false,
     "start_time": "2023-06-18T06:06:22.850063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FlattenMatrix(M, num_digits=8):\n",
    "    '''Convenience function to write CSV files.'''\n",
    "    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "927b3f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:06:22.976433Z",
     "iopub.status.busy": "2023-06-18T06:06:22.975860Z",
     "iopub.status.idle": "2023-06-18T06:06:22.986309Z",
     "shell.execute_reply": "2023-06-18T06:06:22.985670Z"
    },
    "papermill": {
     "duration": 0.052111,
     "end_time": "2023-06-18T06:06:22.988398",
     "exception": false,
     "start_time": "2023-06-18T06:06:22.936287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "with open(f'{src}/test.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        # Skip header.\n",
    "        if i == 0:\n",
    "            continue\n",
    "        test_samples += [row]\n",
    "\n",
    "if dry_run:\n",
    "    for sample in test_samples:\n",
    "        print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e7c9b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:06:23.067879Z",
     "iopub.status.busy": "2023-06-18T06:06:23.067616Z",
     "iopub.status.idle": "2023-06-18T06:06:33.350033Z",
     "shell.execute_reply": "2023-06-18T06:06:33.349229Z"
    },
    "papermill": {
     "duration": 10.324923,
     "end_time": "2023-06-18T06:06:33.352661",
     "exception": false,
     "start_time": "2023-06-18T06:06:23.027738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "F_dict = {}\n",
    "for i, row in enumerate(test_samples):\n",
    "    sample_id, batch_id, image_1_id, image_2_id = row\n",
    "\n",
    "    image_fpath_1 = f'{src}/test_images/{batch_id}/{image_1_id}.png'\n",
    "    image_fpath_2 = f'{src}/test_images/{batch_id}/{image_2_id}.png'\n",
    "\n",
    "    if dry_run:\n",
    "        st = time.time()\n",
    "        \n",
    "    mkps1,mkps2,mconf = inf_qta(image_fpath_1, image_fpath_2, max_image_size=qta_max_img_size, divide_coef=32)\n",
    "    \n",
    "    if len(mkps1) > 7:\n",
    "        rpt_F = 0.20\n",
    "        conf_F = 0.999999\n",
    "        m_iters_F = 200_000\n",
    "        F, inliers_F = cv2.findFundamentalMat(mkps1, mkps2, cv2.USAC_MAGSAC, rpt_F, conf_F, m_iters_F)\n",
    "\n",
    "        if dry_run:\n",
    "            nd = time.time()\n",
    "            print(\"Running time: \", nd - st, \" s\")\n",
    "            \n",
    "        \n",
    "        if F is None:\n",
    "            F_dict[sample_id] = np.zeros((3, 3))\n",
    "            continue\n",
    "        else:\n",
    "            F_dict[sample_id] = F\n",
    "            inliers = inliers_F\n",
    "    else:\n",
    "        F_dict[sample_id] = np.zeros((3, 3))\n",
    "        continue\n",
    "            \n",
    "\n",
    "    if dry_run and i < 3:\n",
    "        F_inliers_total = 0 if F is None else (inliers_F == 1).sum()\n",
    "        print('inliers F', F_inliers_total)\n",
    "        \n",
    "        orig_image_1 = load_torch_kornia_image(image_fpath_1, qta_torch_device, -1)\n",
    "        orig_image_2 = load_torch_kornia_image(image_fpath_2, qta_torch_device, -1)\n",
    "        draw_img_match(orig_image_1, orig_image_2, mkps1, mkps2, inliers)\n",
    "\n",
    "        \n",
    "    try:\n",
    "        # cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        del mkps1, mkps2\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc709675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:06:33.432477Z",
     "iopub.status.busy": "2023-06-18T06:06:33.432237Z",
     "iopub.status.idle": "2023-06-18T06:06:33.437633Z",
     "shell.execute_reply": "2023-06-18T06:06:33.436785Z"
    },
    "papermill": {
     "duration": 0.049045,
     "end_time": "2023-06-18T06:06:33.441226",
     "exception": false,
     "start_time": "2023-06-18T06:06:33.392181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e661d87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:06:33.528251Z",
     "iopub.status.busy": "2023-06-18T06:06:33.527967Z",
     "iopub.status.idle": "2023-06-18T06:06:34.599977Z",
     "shell.execute_reply": "2023-06-18T06:06:34.598910Z"
    },
    "papermill": {
     "duration": 1.121044,
     "end_time": "2023-06-18T06:06:34.602493",
     "exception": false,
     "start_time": "2023-06-18T06:06:33.481449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dry_run is False:\n",
    "    !rm -rf  /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fa0cdc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:06:34.683429Z",
     "iopub.status.busy": "2023-06-18T06:06:34.683129Z",
     "iopub.status.idle": "2023-06-18T06:06:34.690599Z",
     "shell.execute_reply": "2023-06-18T06:06:34.689742Z"
    },
    "papermill": {
     "duration": 0.050698,
     "end_time": "2023-06-18T06:06:34.692844",
     "exception": false,
     "start_time": "2023-06-18T06:06:34.642146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('sample_id,fundamental_matrix\\n')\n",
    "    for sample_id, F in F_dict.items():\n",
    "        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')\n",
    "\n",
    "if dry_run:\n",
    "    !cat submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 427.599154,
   "end_time": "2023-06-18T06:06:37.892620",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-18T05:59:30.293466",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}